{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4bcdcc7bf4ba45eda883f0d7c83be238": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fddc4fe0f83a4113a81ce06650c2b7da",
              "IPY_MODEL_28ce209b64ab463f824834f0eb8afac8",
              "IPY_MODEL_a56c4b88322c4b0c9239384cf6f5ea0f"
            ],
            "layout": "IPY_MODEL_dcc875d06016492a88b05c67b8227215"
          }
        },
        "fddc4fe0f83a4113a81ce06650c2b7da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d652ecfdabbc40d7882ea5a9d5821116",
            "placeholder": "​",
            "style": "IPY_MODEL_225d05dcfd2c4c9b971fad2233fdc011",
            "value": "config.json: 100%"
          }
        },
        "28ce209b64ab463f824834f0eb8afac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_829fe212c0a34791b68449622d51c0d7",
            "max": 794,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f6bacbc0266433c993edc0dc8561130",
            "value": 794
          }
        },
        "a56c4b88322c4b0c9239384cf6f5ea0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9c57ce339b842649378887cac915ba9",
            "placeholder": "​",
            "style": "IPY_MODEL_3419ccdeae844b33a163f228af050286",
            "value": " 794/794 [00:00&lt;00:00, 41.9kB/s]"
          }
        },
        "dcc875d06016492a88b05c67b8227215": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d652ecfdabbc40d7882ea5a9d5821116": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "225d05dcfd2c4c9b971fad2233fdc011": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "829fe212c0a34791b68449622d51c0d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f6bacbc0266433c993edc0dc8561130": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b9c57ce339b842649378887cac915ba9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3419ccdeae844b33a163f228af050286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "faabcc21e6df49728afa0a1383c7812e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31678f995bad478ba6b56d62e62ec4be",
              "IPY_MODEL_cb1c59e5469b4b11a4782065179e0cf0",
              "IPY_MODEL_c0598427e7b8463982936f94aa23adcd"
            ],
            "layout": "IPY_MODEL_be7ec25592e4463cb5d0a7a42d21c352"
          }
        },
        "31678f995bad478ba6b56d62e62ec4be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59e4d2a37e784bd689b07d838dd06a27",
            "placeholder": "​",
            "style": "IPY_MODEL_255babb419194b4bb02711884ceb3d2c",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "cb1c59e5469b4b11a4782065179e0cf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6659e857fcad4fa3abc57dfb69af2a6c",
            "max": 90903017,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7033173605154beeac8d051151fd8229",
            "value": 90903017
          }
        },
        "c0598427e7b8463982936f94aa23adcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45ac1ee2062241b5ad409af48dd4735d",
            "placeholder": "​",
            "style": "IPY_MODEL_257c6eb51bba452d814e876fe45bbf02",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 174MB/s]"
          }
        },
        "be7ec25592e4463cb5d0a7a42d21c352": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59e4d2a37e784bd689b07d838dd06a27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "255babb419194b4bb02711884ceb3d2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6659e857fcad4fa3abc57dfb69af2a6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7033173605154beeac8d051151fd8229": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45ac1ee2062241b5ad409af48dd4735d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "257c6eb51bba452d814e876fe45bbf02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3b365114f2d46d19ba707d3d32458bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_192116cf4d254ec5936c37de802acc00",
              "IPY_MODEL_59f750b6027a4e169158f975d8eb6d4c",
              "IPY_MODEL_6036324aff95405982ca9a1447096e9d"
            ],
            "layout": "IPY_MODEL_2673a6df62904c5ba5e9d51aa2f5d9b7"
          }
        },
        "192116cf4d254ec5936c37de802acc00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64bd9efa49244509b4724b4d8a7725a1",
            "placeholder": "​",
            "style": "IPY_MODEL_8e9f0a46940c4e69a27baef1add80a34",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "59f750b6027a4e169158f975d8eb6d4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00956676af97499186802b24bf100337",
            "max": 316,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4aa3d11ac0fd42ddb596cc234c6d6d80",
            "value": 316
          }
        },
        "6036324aff95405982ca9a1447096e9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d78899e8e89406eb554529456606066",
            "placeholder": "​",
            "style": "IPY_MODEL_7beebf58239b4dfca3a24709e7fe23e0",
            "value": " 316/316 [00:00&lt;00:00, 19.9kB/s]"
          }
        },
        "2673a6df62904c5ba5e9d51aa2f5d9b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64bd9efa49244509b4724b4d8a7725a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e9f0a46940c4e69a27baef1add80a34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00956676af97499186802b24bf100337": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4aa3d11ac0fd42ddb596cc234c6d6d80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d78899e8e89406eb554529456606066": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7beebf58239b4dfca3a24709e7fe23e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7d285b4ce7d4aeebedc15f9c63bb307": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e92233f7a4ef4962ae245da759b779cf",
              "IPY_MODEL_16b3b704125749e4b5e6159bd3659fba",
              "IPY_MODEL_d6773fffa3404617b20ab9dc8cdaed1e"
            ],
            "layout": "IPY_MODEL_f7b4a1b7eaed4e419e03676811ccfe61"
          }
        },
        "e92233f7a4ef4962ae245da759b779cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23a79de8c81749eda96e4c52dd7f069a",
            "placeholder": "​",
            "style": "IPY_MODEL_6211180368c248ea8066bdc5d0f999d2",
            "value": "vocab.txt: 100%"
          }
        },
        "16b3b704125749e4b5e6159bd3659fba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7df842bdbfc4207b1cfe5cf42b9064d",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_48041c38e71b4c789acc21084cd79c6b",
            "value": 231508
          }
        },
        "d6773fffa3404617b20ab9dc8cdaed1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_454208c1a3f4419aaacfe48a4b429f49",
            "placeholder": "​",
            "style": "IPY_MODEL_ad73c1b6ecb14abba1ec5817562d9e47",
            "value": " 232k/232k [00:00&lt;00:00, 4.36MB/s]"
          }
        },
        "f7b4a1b7eaed4e419e03676811ccfe61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23a79de8c81749eda96e4c52dd7f069a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6211180368c248ea8066bdc5d0f999d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7df842bdbfc4207b1cfe5cf42b9064d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48041c38e71b4c789acc21084cd79c6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "454208c1a3f4419aaacfe48a4b429f49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad73c1b6ecb14abba1ec5817562d9e47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d1f1e2c3ec34a28a7165707eeebf636": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9a28ded1c7b417aac3df37b6e934830",
              "IPY_MODEL_b47884c1485542ceb9b628f3a0d5e257",
              "IPY_MODEL_082cec02072947af8791926871b78a6f"
            ],
            "layout": "IPY_MODEL_bc61f7d0b8e44dedaf997f75eab6048a"
          }
        },
        "d9a28ded1c7b417aac3df37b6e934830": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_132a6b0dbafe463b9c1bbd9b504d44a8",
            "placeholder": "​",
            "style": "IPY_MODEL_62dcec81eb244a59bdee614b68e35567",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "b47884c1485542ceb9b628f3a0d5e257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7112eb86414145d09fb45d75ea0c2315",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3deff92639d944d1ba9d9f1cd065fbb2",
            "value": 112
          }
        },
        "082cec02072947af8791926871b78a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bffeb0ebcdb4cb4b0788668c7ba3dfb",
            "placeholder": "​",
            "style": "IPY_MODEL_e99c8c3c24134ccbbbc6dadd10090129",
            "value": " 112/112 [00:00&lt;00:00, 9.12kB/s]"
          }
        },
        "bc61f7d0b8e44dedaf997f75eab6048a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "132a6b0dbafe463b9c1bbd9b504d44a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62dcec81eb244a59bdee614b68e35567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7112eb86414145d09fb45d75ea0c2315": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3deff92639d944d1ba9d9f1cd065fbb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2bffeb0ebcdb4cb4b0788668c7ba3dfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e99c8c3c24134ccbbbc6dadd10090129": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "nDDDuESedN5e",
        "outputId": "2892d904-f16d-44b8-f74d-d0462eafc2f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your CSV file.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bf2fd57b-4d7d-4324-b277-1cfc0cf1e096\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bf2fd57b-4d7d-4324-b277-1cfc0cf1e096\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving wiki_movie_plots_deduped.csv to wiki_movie_plots_deduped.csv\n",
            "Loading 'wiki_movie_plots_deduped.csv' into DataFrame.\n",
            "Data loaded successfully.\n",
            "   Release Year                             Title Origin/Ethnicity  \\\n",
            "0          1901            Kansas Saloon Smashers         American   \n",
            "1          1901     Love by the Light of the Moon         American   \n",
            "2          1901           The Martyred Presidents         American   \n",
            "3          1901  Terrible Teddy, the Grizzly King         American   \n",
            "4          1902            Jack and the Beanstalk         American   \n",
            "\n",
            "                             Director Cast    Genre  \\\n",
            "0                             Unknown  NaN  unknown   \n",
            "1                             Unknown  NaN  unknown   \n",
            "2                             Unknown  NaN  unknown   \n",
            "3                             Unknown  NaN  unknown   \n",
            "4  George S. Fleming, Edwin S. Porter  NaN  unknown   \n",
            "\n",
            "                                           Wiki Page  \\\n",
            "0  https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...   \n",
            "1  https://en.wikipedia.org/wiki/Love_by_the_Ligh...   \n",
            "2  https://en.wikipedia.org/wiki/The_Martyred_Pre...   \n",
            "3  https://en.wikipedia.org/wiki/Terrible_Teddy,_...   \n",
            "4  https://en.wikipedia.org/wiki/Jack_and_the_Bea...   \n",
            "\n",
            "                                                Plot  \n",
            "0  A bartender is working at a saloon, serving dr...  \n",
            "1  The moon, painted with a smiling face hangs ov...  \n",
            "2  The film, just over a minute long, is composed...  \n",
            "3  Lasting just 61 seconds and consisting of two ...  \n",
            "4  The earliest known adaptation of the classic f...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "def load_csv_file():\n",
        "    print(\"Please upload your CSV file.\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if not uploaded:\n",
        "        print(\"No file uploaded.\")\n",
        "        return None\n",
        "\n",
        "    filename = next(iter(uploaded))\n",
        "    print(f\"Loading '{filename}' into DataFrame.\")\n",
        "    df = pd.read_csv(filename)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Load the uploaded CSV file into a DataFrame\n",
        "data = load_csv_file()\n",
        "\n",
        "# Check if the data is loaded successfully\n",
        "if data is not None:\n",
        "    print(\"Data loaded successfully.\")\n",
        "    print(data.head())  # Show the first few rows of the DataFrame\n",
        "else:\n",
        "    print(\"Data loading failed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explantion we loaded the csv file using the upload button"
      ],
      "metadata": {
        "id": "96AkBpzk4qD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def process_data(filename, output_filename):\n",
        "    # Load only the 'Title' and 'Plot' columns from the CSV file\n",
        "    df = pd.read_csv(filename, usecols=['Title', 'Plot'])\n",
        "\n",
        "    # Here you can apply any function to the dataframe if needed\n",
        "    # For example, you could do some data cleaning or processing\n",
        "    # processed_df = your_function(df)\n",
        "\n",
        "    # For this example, we'll just use the original dataframe\n",
        "    processed_df = df\n",
        "\n",
        "    # Save the processed data to a new CSV file\n",
        "    processed_df.to_csv(output_filename, index=False)\n",
        "    print(f\"Data processed and saved to '{output_filename}'.\")\n",
        "\n",
        "# Specify the name of the already uploaded file and the output file\n",
        "input_filename = '/content/wiki_movie_plots_deduped.csv'\n",
        "output_filename = '/content/processed_movies.csv'\n",
        "\n",
        "# Process the data and save it to another file\n",
        "process_data(input_filename, output_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbsajAw4dXqC",
        "outputId": "f5a47310-03eb-4ca9-9808-c7443a90ab9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data processed and saved to '/content/processed_movies.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation: we have removed the extra columns from the dataset and kept \"title\" and \"plot\" columns"
      ],
      "metadata": {
        "id": "itQLlkqW4rtj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcqE860Qdaj_",
        "outputId": "19503500-f48c-44c4-eabc-247b47a344a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-2.6.1-py3-none-any.whl (163 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.3/163.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.38.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 sentence-transformers-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we have installed the sentence transformer libraries"
      ],
      "metadata": {
        "id": "S2sPZdKH4v0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "# Load your dataset\n",
        "dataset = pd.read_csv('/content/processed_movies.csv')\n",
        "\n",
        "# Combine 'Title' and 'Plot' into a single text passage\n",
        "dataset['text'] = dataset['Title'] + \": \" + dataset['Plot']\n",
        "\n",
        "# Convert the dataset to a list of texts for processing\n",
        "corpus = dataset['text'].tolist()\n",
        "\n",
        "# Tokenize the corpus for BM25\n",
        "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "# Initialize the bi-encoder model and pre-compute corpus embeddings\n",
        "bi_encoder = SentenceTransformer('nq-distilbert-base-v1')\n",
        "corpus_embeddings = bi_encoder.encode(corpus, convert_to_tensor=True)\n",
        "\n",
        "# Define the search function\n",
        "def search(query):\n",
        "    # Perform BM25 search and get top 100 results as an example\n",
        "    bm25_scores = bm25.get_scores(query.split(\" \"))\n",
        "    bm25_ranking = np.argsort(bm25_scores)[::-1][:100]\n",
        "\n",
        "    # Semantic search with pre-computed embeddings\n",
        "    query_embedding = bi_encoder.encode(query, convert_to_tensor=True)\n",
        "    semantic_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
        "    semantic_ranking = torch.argsort(semantic_scores, descending=True).cpu().numpy()[:100]\n",
        "\n",
        "    # Combine BM25 and semantic rankings using a reranker (CrossEncoder)\n",
        "    cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "    combined_idxs = np.unique(np.concatenate([bm25_ranking, semantic_ranking]))\n",
        "    cross_inp = [[query, corpus[idx]] for idx in combined_idxs[:50]]  # Top 50 for reranking to reduce computation\n",
        "    cross_scores = cross_encoder.predict(cross_inp)\n",
        "\n",
        "    # Sort and select the top 5 results\n",
        "    top_results = sorted(zip(combined_idxs, cross_scores), key=lambda x: x[1], reverse=True)[:5]\n",
        "    return [(corpus[idx], score) for idx, score in top_results]\n",
        "\n",
        "# Example search query\n",
        "query = \"Documentaries showcasing indigenous peoples' survival and daily life in Arctic regions\"\n",
        "results = search(query)\n",
        "\n",
        "# Display the top 5 results\n",
        "for text, score in results:\n",
        "    print(f\"Text: {text}\\nScore: {score}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718,
          "referenced_widgets": [
            "4bcdcc7bf4ba45eda883f0d7c83be238",
            "fddc4fe0f83a4113a81ce06650c2b7da",
            "28ce209b64ab463f824834f0eb8afac8",
            "a56c4b88322c4b0c9239384cf6f5ea0f",
            "dcc875d06016492a88b05c67b8227215",
            "d652ecfdabbc40d7882ea5a9d5821116",
            "225d05dcfd2c4c9b971fad2233fdc011",
            "829fe212c0a34791b68449622d51c0d7",
            "5f6bacbc0266433c993edc0dc8561130",
            "b9c57ce339b842649378887cac915ba9",
            "3419ccdeae844b33a163f228af050286",
            "faabcc21e6df49728afa0a1383c7812e",
            "31678f995bad478ba6b56d62e62ec4be",
            "cb1c59e5469b4b11a4782065179e0cf0",
            "c0598427e7b8463982936f94aa23adcd",
            "be7ec25592e4463cb5d0a7a42d21c352",
            "59e4d2a37e784bd689b07d838dd06a27",
            "255babb419194b4bb02711884ceb3d2c",
            "6659e857fcad4fa3abc57dfb69af2a6c",
            "7033173605154beeac8d051151fd8229",
            "45ac1ee2062241b5ad409af48dd4735d",
            "257c6eb51bba452d814e876fe45bbf02",
            "d3b365114f2d46d19ba707d3d32458bc",
            "192116cf4d254ec5936c37de802acc00",
            "59f750b6027a4e169158f975d8eb6d4c",
            "6036324aff95405982ca9a1447096e9d",
            "2673a6df62904c5ba5e9d51aa2f5d9b7",
            "64bd9efa49244509b4724b4d8a7725a1",
            "8e9f0a46940c4e69a27baef1add80a34",
            "00956676af97499186802b24bf100337",
            "4aa3d11ac0fd42ddb596cc234c6d6d80",
            "7d78899e8e89406eb554529456606066",
            "7beebf58239b4dfca3a24709e7fe23e0",
            "d7d285b4ce7d4aeebedc15f9c63bb307",
            "e92233f7a4ef4962ae245da759b779cf",
            "16b3b704125749e4b5e6159bd3659fba",
            "d6773fffa3404617b20ab9dc8cdaed1e",
            "f7b4a1b7eaed4e419e03676811ccfe61",
            "23a79de8c81749eda96e4c52dd7f069a",
            "6211180368c248ea8066bdc5d0f999d2",
            "c7df842bdbfc4207b1cfe5cf42b9064d",
            "48041c38e71b4c789acc21084cd79c6b",
            "454208c1a3f4419aaacfe48a4b429f49",
            "ad73c1b6ecb14abba1ec5817562d9e47",
            "9d1f1e2c3ec34a28a7165707eeebf636",
            "d9a28ded1c7b417aac3df37b6e934830",
            "b47884c1485542ceb9b628f3a0d5e257",
            "082cec02072947af8791926871b78a6f",
            "bc61f7d0b8e44dedaf997f75eab6048a",
            "132a6b0dbafe463b9c1bbd9b504d44a8",
            "62dcec81eb244a59bdee614b68e35567",
            "7112eb86414145d09fb45d75ea0c2315",
            "3deff92639d944d1ba9d9f1cd065fbb2",
            "2bffeb0ebcdb4cb4b0788668c7ba3dfb",
            "e99c8c3c24134ccbbbc6dadd10090129"
          ]
        },
        "id": "2oikRwDddeFI",
        "outputId": "26d6743f-8404-4bc3-afdc-1d2065ba3c33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4bcdcc7bf4ba45eda883f0d7c83be238"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "faabcc21e6df49728afa0a1383c7812e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3b365114f2d46d19ba707d3d32458bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7d285b4ce7d4aeebedc15f9c63bb307"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d1f1e2c3ec34a28a7165707eeebf636"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: The Savage Innocents: Inuk, an Inuk, kills a priest who rejects his traditional offer of food and his wife's company. Pursued by white policemen, Inuk saves the life of one of them, resulting in a final confrontation in which the surviving cop must decide between his commitment to law enforcement and his gratitude to Inuk.\r\n",
            "The film's themes include Inuit survival in the extreme arctic wilderness, as well as their raw existence and struggle to maintain their lifestyle against encroaching civilization.\n",
            "Score: 0.04700668156147003\n",
            "\n",
            "Text: Nanook of the North: The documentary follows the lives of an Inuk, Nanook, and his family as they travel, search for food, and trade in the Ungava Peninsula of northern Quebec, Canada. Nanook; his wife, Nyla; and their family are introduced as fearless heroes who endure rigors no other race could survive. The audience sees Nanook, often with his family, hunt a walrus, build an igloo, go about his day, and perform other tasks.\n",
            "Score: -4.554294586181641\n",
            "\n",
            "Text: The White Dawn: When three whalers become stranded in Northern Canada’s Arctic in 1896, they are rescued by Inuit. In the beginning, the Inuit accept the strangers' European ways, but as this increasingly influences and affects their customs, things slowly fall apart and cultural tension grows until the climax.\n",
            "Score: -5.854590892791748\n",
            "\n",
            "Text: Iceman: Anthropologist Stanley Shephard (Timothy Hutton) is brought to an arctic base when explorers discover the body of a prehistoric man (John Lone) who has been frozen in a block of ice for 40,000 years. After thawing the body to perform an autopsy, scientists discover to their amazement a real possibility to revive him and their attempt to resuscitate the \"iceman\" proves successful.\r\n",
            "While being revived, the dazed caveman is alarmed by the surgical-masked figures; only Shephard has the presence of mind to remove his mask and reveal his humanity and somewhat familiar face to the terrified caveman, permitting the caveman to settle back into a more peaceful sleep and make a full recovery.\r\n",
            "The scientists place the caveman in an artificial, simulated environment for study. The caveman quickly discovers the modern apparatus and environmental controls, and understands he is still far from home. Shephard believes that the caveman's culture may provide clues to learning about the human body's adaptability, citing ceremonies such as firewalking and the Sun Dance. Several other scientists in the research base see the potential in studying the caveman's DNA and his survival in the ice, as they see it mainly as a case to advance medical science by \"freezing\" the sick or injured in order to suspend their bodies until treatment.\r\n",
            "Shephard's affinity with the caveman grows to the degree that he begins to defend the caveman's right to be considered a human being and not a scientific specimen. Despite opposition from the rest of the staff, Shephard initiates an encounter with the caveman. Shephard names him \"Charlie\" after the iceman introduces himself as \"Char-u\". Shephard and Charlie bond, but it becomes obvious to the anthropologist that Charlie misses his world; he is terrified and confused by the unknown world in which he awakens.\r\n",
            "An eminent linguist is brought to the Arctic base to help understand Charlie's language. As Shephard begins to communicate with Charlie, he realizes that he will never be able to help Charlie understand that the world and community he came from have long since disappeared. This fact is made even more poignant when Shephard introduces Charlie to a female colleague, Dr. Diane Brady (Lindsay Crouse). Assuming that the woman is Shephard's mate, Charlie makes chalk marks which indicate that he likely was a married man with children before he was frozen.\r\n",
            "Shephard strives to understand what motivates Charlie and why, of all the cavemen, he should survive being frozen. At one point, Shephard begins to sing \"Heart of Gold\", inspiring Charlie to sing one of his own songs. Charlie's seemingly incidental bird-like line drawings in the ground resembling body markings on his chest take on a new significance when the base's helicopter strays over the roof of the base's artificial tropical eco-zone, causing Charlie to take on an almost obsessive zeal as he climbs towards the roof. Shouting the word Beedha over and over, he lifts his arms towards the helicopter in a sign of obvious worship. Even though the helicopter pulls away from the dome, Shephard knows that Charlie can now think of nothing else.\r\n",
            "Charlie escapes after watching Shephard exit the biosphere and in a panic of seeing unfamiliar modern devices and believing there are enemies, spears Maynard (James Tolkan), one of the base's technicians. Recapturing Charlie, the other scientists, led by Dr. Singe (David Strathairn), focus on what they can learn from him, using him as a subject rather than a person. They attempt to re-freeze the iceman in order to study the effect of thawing on Charlie's physiology and determine what benefit may result. The incident goes awry as Charlie nearly dies in the attempt.\r\n",
            "Shephard consults local Inuit who recognize the name that Charlie chanted and explain that it is a mythical bird – a messenger from the gods who comes to take good people to heaven, while sinners are sent to a kind of purgatory. Shephard has long known that Charlie has a spiritual dimension and now sees that he was on a dreamwalk pilgrimage, a mythical quest for redemption. His people were dying in the sudden ice age; he must have offered himself to the gods in the form of a self-sacrifice or appealing to the gods to redeem his tribe.\r\n",
            "Shephard defies all protocol to help Charlie to escape, because he realizes that Charlie would never survive in the modern world, and Charlie's peace-of-mind and fulfillment are of prime importance to Shephard. Delighted with his freedom, Charlie races on ahead of Shephard as they pass by glaciers and vast ice-shelves, and a crevasse opens up in front of Shephard, cutting him off from Charlie. Meanwhile, the other personnel give chase.\r\n",
            "The helicopter emerges over an ice-shelf before Charlie. Shephard looks on helplessly as Charlie climbs up towards the aircraft and grabs hold of one of its landing skis. In an attempt to evade Charlie's grasp, the helicopter pilot pulls up, but Charlie dangles beneath the aircraft while it continues to climb high into the sky. The co-pilot offers a hand to Charlie to save him, but an elated and ecstatic Charlie cries out and releases the aircraft, seeming to float through the sky while he plunges.\r\n",
            "Shephard's initial horror turns into joy as he realizes that Charlie has reached his goal.\n",
            "Score: -6.294935703277588\n",
            "\n",
            "Text: Daughters of the Dust: Daughters of the Dust is set in 1902 among the members of the Peazant family, Gullah islanders who live at Ibo Landing on St. Simons Island, off the Georgia coast.[5] Their ancestors were brought there as enslaved people centuries ago, and the islanders developed a language and culture that was creolized from West Africans of Ibo, Yoruba, Kikongo, Mende, and Twi origin.[6] Developed in their relative isolation of large plantations on the islands, the enslaved peoples' unique culture and language have endured over time. Their dialogue is in Gullah creole.[5]\r\n",
            "Narrated by the Unborn Child, the future daughter of Eli and Eula, whose voice is influenced by accounts of her ancestors, the film presents poetic visual images and circular narrative structures to represent the past, present and future for the Gullah, the majority of whom are about to embark for the mainland and a more modern way of life. The old ways are represented by community matriarch Nana Peazant, who practices African and Caribbean spiritual rituals and who says of the Unborn Child, \"We are two people in one body. The last of the old and the first of the new.\"\r\n",
            "Contrasting cousins, Viola, a devout Christian, and Yellow Mary, a free spirit who has brought her lover, Trula, from the city, arrive at the island by canoe from their homes on the mainland for a last dinner with their family. Yellow Mary plans to leave for Nova Scotia after her visit. Mr. Snead, a mainland photographer, accompanies Viola and takes portraits of the islanders before they leave their way of life forever. Intertwined with these narratives is the marital rift between Eli and his wife Eula, who is about to give birth after being raped by a white man on the mainland. Eli struggles with the fact that the unborn child may not be his.\r\n",
            "Several other family members' stories unfold between these narratives. They include Haagar, a cousin who finds the old spiritual beliefs and provincialism of the island \"backwards,\" and is impatient to leave for a more modern society with its educational and economic opportunities. Her daughter Iona longs to be with her secret lover St. Julien Lastchild, a Native American, who will not leave the island.\r\n",
            "While the women prepare a traditional meal for the feast, which includes okra, yams and shellfish prepared at the beach, the men gather nearby in groups to talk. The children and teenagers practice religious rites on the beach and have a Bible-study session with Viola. Bilal Muhammad leads a Muslim prayer. Nana evokes the spirits of the family's ancestors who worked on the island's indigo plantations. Eula and Eli reveal the history and folklore of the slave uprising and mass suicide at Igbo Landing. The Peazant family members make their final decisions to leave the island for a new beginning, or stay behind and maintain their way of life.\n",
            "Score: -8.080719947814941\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We constructed a model using semantic search to get five relevant movie title and plots based on plot passed as a input query"
      ],
      "metadata": {
        "id": "QNYFfoDE5CHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from rank_bm25 import BM25Okapi\n",
        "import numpy as np\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_csv('/content/processed_movies.csv')\n",
        "\n",
        "# Combine 'Title' and 'Plot' for indexing\n",
        "corpus = [f\"{row['Title']}: {row['Plot']}\" for _, row in data.iterrows()]\n",
        "\n",
        "# Tokenize the corpus for BM25\n",
        "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "# Load the sentence transformer model\n",
        "model = SentenceTransformer('nq-distilbert-base-v1')\n",
        "\n",
        "# Encode the corpus using the model\n",
        "corpus_embeddings = model.encode(corpus, convert_to_tensor=True)\n",
        "\n",
        "# Function to search the corpus\n",
        "def search(query: str, top_k: int = 5):\n",
        "    # BM25 search\n",
        "    bm25_scores = bm25.get_scores(query.split(\" \"))\n",
        "    bm25_ranking = np.argsort(bm25_scores)[::-1][:top_k]\n",
        "\n",
        "    # Semantic search\n",
        "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
        "    similarities = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
        "    semantic_ranking = torch.argsort(similarities, descending=True).cpu().numpy()[:top_k]\n",
        "\n",
        "    # Combine results from BM25 and semantic search\n",
        "    combined_indices = np.unique(np.concatenate([bm25_ranking, semantic_ranking]))\n",
        "\n",
        "    # Sort combined indices by BM25 scores to get top results\n",
        "    combined_scores = bm25_scores[combined_indices]\n",
        "    top_indices = np.argsort(combined_scores)[::-1][:top_k]\n",
        "\n",
        "    print(\"Query:\", query)\n",
        "    print(\"\\nTop 5 most similar movies in the corpus:\")\n",
        "    for idx in top_indices:\n",
        "        print(data.iloc[combined_indices[idx]]['Title'], \"(BM25 Score: {:.4f})\".format(bm25_scores[combined_indices[idx]]))\n",
        "\n",
        "# Get a search query from the user\n",
        "user_query = input(\"Enter your movie plot query: \")\n",
        "search(user_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzUOnPHmnX4E",
        "outputId": "9e7c2e7f-65af-4824-cd52-5a5dc2b5360c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your movie plot query: Documentaries showcasing indigenous peoples' survival and daily life in Arctic regions\n",
            "Query: Documentaries showcasing indigenous peoples' survival and daily life in Arctic regions\n",
            "\n",
            "Top 5 most similar movies in the corpus:\n",
            "Papilio Buddha (BM25 Score: 27.8773)\n",
            "Not with My Wife, You Don't! (BM25 Score: 24.9000)\n",
            "Uriyadi (BM25 Score: 23.2196)\n",
            "Ladies Only (BM25 Score: 22.2146)\n",
            "Being Caribou (BM25 Score: 22.1769)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us calculate the values of @Recall and @MRR now. Recall@k = true positives@k + true negatives@k\n",
        "\n",
        "Documentaries showcasing indigenous pepoles survival and daily life in arctic regions The top 5 results for this query are : Papilio Buddha,Not with My Wife, You Don't!,Uriyadi ,Ladies Only ,Being Caribou out of these five results, Papilio Buddha- RELEVANT, Not with my wife - IRRELEVANT, The Uriyadi - IRRELEVANT, Being Caribou- Irrelevant, Being Caribou - RELEVANT\n",
        "\n",
        "Recall@1 = 1/(1+1)= 0.5\n",
        "\n",
        "The metric is useful when we our system to return the best relevant item and want that item to be at higher position. The top 5 results for this query are : Papilio Buddha,Not with My Wife, You Don't!,Uriyadi ,Ladies Only ,Being Caribou For this query, the reciporcal rank is 1/1 and MRR=1 (as the first correct item is at position)"
      ],
      "metadata": {
        "id": "8zoHZ6Bd5b2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from rank_bm25 import BM25Okapi\n",
        "import numpy as np\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_csv('/content/processed_movies.csv')\n",
        "\n",
        "# Combine 'Title' and 'Plot' for indexing\n",
        "corpus = [f\"{row['Title']}: {row['Plot']}\" for _, row in data.iterrows()]\n",
        "\n",
        "# Tokenize the corpus for BM25\n",
        "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "# Load the sentence transformer model\n",
        "model = SentenceTransformer('nq-distilbert-base-v1')\n",
        "\n",
        "# Encode the corpus using the model\n",
        "corpus_embeddings = model.encode(corpus, convert_to_tensor=True)\n",
        "\n",
        "# Function to search the corpus\n",
        "def search(query: str, top_k: int = 5):\n",
        "    # BM25 search\n",
        "    bm25_scores = bm25.get_scores(query.split(\" \"))\n",
        "    bm25_ranking = np.argsort(bm25_scores)[::-1][:top_k]\n",
        "\n",
        "    # Semantic search\n",
        "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
        "    similarities = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
        "    semantic_ranking = torch.argsort(similarities, descending=True).cpu().numpy()[:top_k]\n",
        "\n",
        "    # Combine results from BM25 and semantic search\n",
        "    combined_indices = np.unique(np.concatenate([bm25_ranking, semantic_ranking]))\n",
        "\n",
        "    # Sort combined indices by BM25 scores to get top results\n",
        "    combined_scores = bm25_scores[combined_indices]\n",
        "    top_indices = np.argsort(combined_scores)[::-1][:top_k]\n",
        "\n",
        "    print(\"Query:\", query)\n",
        "    print(\"\\nTop 5 most similar movies in the corpus:\")\n",
        "    for idx in top_indices:\n",
        "        print(data.iloc[combined_indices[idx]]['Title'], \"(BM25 Score: {:.4f})\".format(bm25_scores[combined_indices[idx]]))\n",
        "\n",
        "# Get a search query from the user\n",
        "user_query = input(\"Enter your movie plot query: \")\n",
        "search(user_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCeZKGNzpc1P",
        "outputId": "d286be0f-4013-4fac-9011-671ca6cb0700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your movie plot query: Western romance\n",
            "Query: Western romance\n",
            "\n",
            "Top 5 most similar movies in the corpus:\n",
            "Hyderabad Blues (BM25 Score: 13.8661)\n",
            "Out of This World (BM25 Score: 13.1966)\n",
            "El Akhar (The Other) (BM25 Score: 12.3279)\n",
            "Blighty (BM25 Score: 11.7846)\n",
            "The Big Show (BM25 Score: 10.9925)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us calculate the values of @Recall and @MRR now. Recall@k = true positives@k + true negatives@k\n",
        "\n",
        "Documentaries showcasing indigenous pepoles survival and daily life in arctic regions The top 5 results for this query are : Hyderabad Blues,out of this world, El akhar,Blightly, The big show out of these five results, Hyderabad Blues - RELEVANT, Out of this world - IRRELEVANT, El akhar - IRRELEVANT, Blightly - Irrelevant, The big show - RELEVANT\n",
        "\n",
        " Recall@1 = 1/(1+1)= 0.5\n",
        "\n",
        "The metric is useful when we our system to return the best relevant item and want that item to be at higher position. The top 5 results for this query are : Hyderabad Blues,out of this world, El akhar,Blightly, The big show For this query, the reciporcal rank is 1/1 and MRR=1 (as the first correct item is at position)"
      ],
      "metadata": {
        "id": "Cp0f2U5Z5dw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from rank_bm25 import BM25Okapi\n",
        "import numpy as np\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_csv('/content/processed_movies.csv')\n",
        "\n",
        "# Combine 'Title' and 'Plot' for indexing\n",
        "corpus = [f\"{row['Title']}: {row['Plot']}\" for _, row in data.iterrows()]\n",
        "\n",
        "# Tokenize the corpus for BM25\n",
        "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "# Load the sentence transformer model\n",
        "model = SentenceTransformer('nq-distilbert-base-v1')\n",
        "\n",
        "# Encode the corpus using the model\n",
        "corpus_embeddings = model.encode(corpus, convert_to_tensor=True)\n",
        "\n",
        "# Function to search the corpus\n",
        "def search(query: str, top_k: int = 5):\n",
        "    # BM25 search\n",
        "    bm25_scores = bm25.get_scores(query.split(\" \"))\n",
        "    bm25_ranking = np.argsort(bm25_scores)[::-1][:top_k]\n",
        "\n",
        "    # Semantic search\n",
        "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
        "    similarities = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
        "    semantic_ranking = torch.argsort(similarities, descending=True).cpu().numpy()[:top_k]\n",
        "\n",
        "    # Combine results from BM25 and semantic search\n",
        "    combined_indices = np.unique(np.concatenate([bm25_ranking, semantic_ranking]))\n",
        "\n",
        "    # Sort combined indices by BM25 scores to get top results\n",
        "    combined_scores = bm25_scores[combined_indices]\n",
        "    top_indices = np.argsort(combined_scores)[::-1][:top_k]\n",
        "\n",
        "    print(\"Query:\", query)\n",
        "    print(\"\\nTop 5 most similar movies in the corpus:\")\n",
        "    for idx in top_indices:\n",
        "        print(data.iloc[combined_indices[idx]]['Title'], \"(BM25 Score: {:.4f})\".format(bm25_scores[combined_indices[idx]]))\n",
        "\n",
        "# Get a search query from the user\n",
        "user_query = input(\"Enter your movie plot query: \")\n",
        "search(user_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rv7ZxmqJpgzA",
        "outputId": "4a5678ff-d39f-42d3-8628-18e9ab561732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your movie plot query: \"Silent film about a Parisian star moving to Egypt, leaving her husband for a baron, and later reconciling after finding her family in poverty in Cairo\n",
            "Query: \"Silent film about a Parisian star moving to Egypt, leaving her husband for a baron, and later reconciling after finding her family in poverty in Cairo\n",
            "\n",
            "Top 5 most similar movies in the corpus:\n",
            "Sahara (BM25 Score: 66.1401)\n",
            "Inspiration (BM25 Score: 63.4763)\n",
            "Ruby Cairo (BM25 Score: 61.3989)\n",
            "Medusa: Dare to Be Truthful (BM25 Score: 60.9099)\n",
            "He Who Gets Slapped (BM25 Score: 60.6370)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us calculate the values of @Recall and @MRR now. Recall@k = true positives@k + true negatives@k\n",
        "\n",
        "Documentaries showcasing indigenous pepoles survival and daily life in arctic regions The top 5 results for this query are : Sahara,Inspiration,Ruby Cario,Medusa,He who gets slapped out of these five results, Sahara - RELEVANT, Inspiration - IRRELEVANT, Ruby Cario - RELEVANT, Medusa - relevant, He who gets slapped - RELEVANT\n",
        "\n",
        " Recall@1 = 1/(1+1)= 0.5\n",
        "\n",
        "The metric is useful when we our system to return the best relevant item and want that item to be at higher position. The top 5 results for this query are :Sahara,Inspiration,Ruby Cario,Medusa,He who gets slapped For this query, the reciporcal rank is 1/1 and MRR=1 (as the first correct item is at position)"
      ],
      "metadata": {
        "id": "ycQxYa0g5f74"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from rank_bm25 import BM25Okapi\n",
        "import numpy as np\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_csv('/content/processed_movies.csv')\n",
        "\n",
        "# Combine 'Title' and 'Plot' for indexing\n",
        "corpus = [f\"{row['Title']}: {row['Plot']}\" for _, row in data.iterrows()]\n",
        "\n",
        "# Tokenize the corpus for BM25\n",
        "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "# Load the sentence transformer model\n",
        "model = SentenceTransformer('nq-distilbert-base-v1')\n",
        "\n",
        "# Encode the corpus using the model\n",
        "corpus_embeddings = model.encode(corpus, convert_to_tensor=True)\n",
        "\n",
        "# Function to search the corpus\n",
        "def search(query: str, top_k: int = 5):\n",
        "    # BM25 search\n",
        "    bm25_scores = bm25.get_scores(query.split(\" \"))\n",
        "    bm25_ranking = np.argsort(bm25_scores)[::-1][:top_k]\n",
        "\n",
        "    # Semantic search\n",
        "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
        "    similarities = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
        "    semantic_ranking = torch.argsort(similarities, descending=True).cpu().numpy()[:top_k]\n",
        "\n",
        "    # Combine results from BM25 and semantic search\n",
        "    combined_indices = np.unique(np.concatenate([bm25_ranking, semantic_ranking]))\n",
        "\n",
        "    # Sort combined indices by BM25 scores to get top results\n",
        "    combined_scores = bm25_scores[combined_indices]\n",
        "    top_indices = np.argsort(combined_scores)[::-1][:top_k]\n",
        "\n",
        "    print(\"Query:\", query)\n",
        "    print(\"\\nTop 5 most similar movies in the corpus:\")\n",
        "    for idx in top_indices:\n",
        "        print(data.iloc[combined_indices[idx]]['Title'], \"(BM25 Score: {:.4f})\".format(bm25_scores[combined_indices[idx]]))\n",
        "\n",
        "# Get a search query from the user\n",
        "user_query = input(\"Enter your movie plot query: \")\n",
        "search(user_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwUUteoLpjxi",
        "outputId": "6ebc90c5-1f3b-46ea-f267-bec77c16a0f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your movie plot query: Comedy film, office disguises, boss's daughter, elopement\n",
            "Query: Comedy film, office disguises, boss's daughter, elopement\n",
            "\n",
            "Top 5 most similar movies in the corpus:\n",
            "Floodtide (BM25 Score: 14.8156)\n",
            "Class of Nuke 'Em High 3: The Good, the Bad and the Subhumanoid (BM25 Score: 13.7324)\n",
            "The Milkman (BM25 Score: 13.0447)\n",
            "Delete My Love (BM25 Score: 12.7846)\n",
            "The Boy Friend (BM25 Score: 12.6869)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us calculate the values of @Recall and @MRR now. Recall@k = true positives@k + true negatives@k\n",
        "\n",
        "Documentaries showcasing indigenous pepoles survival and daily life in arctic regions The top 5 results for this query are : Floodtide,class of nuke the milkman,delete my love,The boy friend out of these five results,\n",
        "\n",
        "Recall@1 = 1/(1+1)= 0.5\n",
        "\n",
        "The metric is useful when we our system to return the best relevant item and want that item to be at higher position. The top 5 results for this query are : Floodtide,class of nuke the milkman,delete my love,The boy friend For this query, the reciporcal rank is 1/1 and MRR=1 (as the first correct item is at position)"
      ],
      "metadata": {
        "id": "bcZ1Wuch5hZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from rank_bm25 import BM25Okapi\n",
        "import numpy as np\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_csv('/content/processed_movies.csv')\n",
        "\n",
        "# Combine 'Title' and 'Plot' for indexing\n",
        "corpus = [f\"{row['Title']}: {row['Plot']}\" for _, row in data.iterrows()]\n",
        "\n",
        "# Tokenize the corpus for BM25\n",
        "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "# Load the sentence transformer model\n",
        "model = SentenceTransformer('nq-distilbert-base-v1')\n",
        "\n",
        "# Encode the corpus using the model\n",
        "corpus_embeddings = model.encode(corpus, convert_to_tensor=True)\n",
        "\n",
        "# Function to search the corpus\n",
        "def search(query: str, top_k: int = 5):\n",
        "    # BM25 search\n",
        "    bm25_scores = bm25.get_scores(query.split(\" \"))\n",
        "    bm25_ranking = np.argsort(bm25_scores)[::-1][:top_k]\n",
        "\n",
        "    # Semantic search\n",
        "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
        "    similarities = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
        "    semantic_ranking = torch.argsort(similarities, descending=True).cpu().numpy()[:top_k]\n",
        "\n",
        "    # Combine results from BM25 and semantic search\n",
        "    combined_indices = np.unique(np.concatenate([bm25_ranking, semantic_ranking]))\n",
        "\n",
        "    # Sort combined indices by BM25 scores to get top results\n",
        "    combined_scores = bm25_scores[combined_indices]\n",
        "    top_indices = np.argsort(combined_scores)[::-1][:top_k]\n",
        "\n",
        "    print(\"Query:\", query)\n",
        "    print(\"\\nTop 5 most similar movies in the corpus:\")\n",
        "    for idx in top_indices:\n",
        "        print(data.iloc[combined_indices[idx]]['Title'], \"(BM25 Score: {:.4f})\".format(bm25_scores[combined_indices[idx]]))\n",
        "\n",
        "# Get a search query from the user\n",
        "user_query = input(\"Enter your movie plot query: \")\n",
        "search(user_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2A0r39dplTb",
        "outputId": "7c8b8dc0-c959-4ab2-bc3f-7d8751073595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your movie plot query: \"Lost film, Cleopatra charms Caesar, plots world rule, treasures from mummy, revels with Antony, tragic end with serpent in Alexandria\n",
            "Query: \"Lost film, Cleopatra charms Caesar, plots world rule, treasures from mummy, revels with Antony, tragic end with serpent in Alexandria\n",
            "\n",
            "Top 5 most similar movies in the corpus:\n",
            "Cleopatra (BM25 Score: 48.7561)\n",
            "Cleopatra (BM25 Score: 48.7561)\n",
            "Cleopatra (BM25 Score: 46.2703)\n",
            "Serpent of the Nile (BM25 Score: 41.2549)\n",
            "Cleopatra (BM25 Score: 38.8077)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us calculate the values of @Recall and @MRR now. Recall@k = true positives@k + true negatives@k\n",
        "\n",
        "Documentaries showcasing indigenous pepoles survival and daily life in arctic regions  out of these five results,  Recall@1 = 1/(1+1)= 0.5\n",
        "The metric is useful when we our system to return the best relevant item and want that item to be at higher position. The top 5 results for this query are : For this query, the reciporcal rank is 1/1 and MRR=1 (as the first correct item is at position)"
      ],
      "metadata": {
        "id": "cl0R-j6t5ivE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from rank_bm25 import BM25Okapi\n",
        "import numpy as np\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_csv('/content/processed_movies.csv')\n",
        "\n",
        "# Combine 'Title' and 'Plot' for indexing\n",
        "corpus = [f\"{row['Title']}: {row['Plot']}\" for _, row in data.iterrows()]\n",
        "\n",
        "# Tokenize the corpus for BM25\n",
        "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "# Load the sentence transformer model\n",
        "model = SentenceTransformer('nq-distilbert-base-v1')\n",
        "\n",
        "# Encode the corpus using the model\n",
        "corpus_embeddings = model.encode(corpus, convert_to_tensor=True)\n",
        "\n",
        "# Function to search the corpus\n",
        "def search(query: str, top_k: int = 5):\n",
        "    # BM25 search\n",
        "    bm25_scores = bm25.get_scores(query.split(\" \"))\n",
        "    bm25_ranking = np.argsort(bm25_scores)[::-1][:top_k]\n",
        "\n",
        "    # Semantic search\n",
        "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
        "    similarities = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
        "    semantic_ranking = torch.argsort(similarities, descending=True).cpu().numpy()[:top_k]\n",
        "\n",
        "    # Combine results from BM25 and semantic search\n",
        "    combined_indices = np.unique(np.concatenate([bm25_ranking, semantic_ranking]))\n",
        "\n",
        "    # Sort combined indices by BM25 scores to get top results\n",
        "    combined_scores = bm25_scores[combined_indices]\n",
        "    top_indices = np.argsort(combined_scores)[::-1][:top_k]\n",
        "\n",
        "    print(\"Query:\", query)\n",
        "    print(\"\\nTop 5 most similar movies in the corpus:\")\n",
        "    for idx in top_indices:\n",
        "        print(data.iloc[combined_indices[idx]]['Title'], \"(BM25 Score: {:.4f})\".format(bm25_scores[combined_indices[idx]]))\n",
        "\n",
        "# Get a search query from the user\n",
        "user_query = input(\"Enter your movie plot query: \")\n",
        "search(user_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HE6GY4hpmy_",
        "outputId": "3cc55c98-7a35-495e-f328-6cc2ee63493e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your movie plot query: Denis Gage Deane-Tanner\n",
            "Query: Denis Gage Deane-Tanner\n",
            "\n",
            "Top 5 most similar movies in the corpus:\n",
            "Captain Alvarez (BM25 Score: 25.8007)\n",
            "Indecent Proposal (BM25 Score: 17.0718)\n",
            "I Love You, Beth Cooper (BM25 Score: 15.9906)\n",
            "Yolki 6 (BM25 Score: 14.5183)\n",
            "The Strange Door (BM25 Score: 14.0004)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us calculate the values of @Recall and @MRR now. Recall@k = true positives@k + true negatives@k\n",
        "\n",
        "Documentaries showcasing indigenous pepoles survival and daily life in arctic regions The top 5 results for this query are : capatain Alvarez,indecent proposal,ilove you, yolki, The stranger door out of these five results,\n",
        " Recall@1 = 1/(1+2)= 0.33\n",
        "The metric is useful when we our system to return the best relevant item and want that item to be at higher position. The top 5 results for this query are :capatain Alvarez,indecent proposal,ilove you, yolki, The stranger door out of these five results, For this query, the reciporcal rank is 1/3 and MRR=3"
      ],
      "metadata": {
        "id": "SBj81xAh5lAz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now with Semantic Search and Bm25 Model. We are also implementing Re Rank model to combine the results"
      ],
      "metadata": {
        "id": "nMSPQqEwsGI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
        "from rank_bm25 import BM25Okapi\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_csv('/content/processed_movies.csv')\n",
        "\n",
        "# Combine 'Title' and 'Plot' for indexing\n",
        "corpus = [f\"{row['Title']}: {row['Plot']}\" for _, row in data.iterrows()]\n",
        "\n",
        "# Tokenize the corpus for BM25\n",
        "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "# Load the bi-encoder model\n",
        "bi_encoder = SentenceTransformer('nq-distilbert-base-v1')\n",
        "corpus_embeddings = bi_encoder.encode(corpus, convert_to_tensor=True)\n",
        "\n",
        "# Load the cross-encoder model for reranking\n",
        "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "\n",
        "# Function to search and rerank the corpus\n",
        "def search_and_rerank(query: str, top_k: int = 5):\n",
        "    # Perform BM25 search to get a broader set of candidates\n",
        "    bm25_scores = bm25.get_scores(query.split(\" \"))\n",
        "    bm25_top_idx = np.argsort(bm25_scores)[::-1][:100]\n",
        "\n",
        "    # Semantic search to refine the candidates\n",
        "    query_embedding = bi_encoder.encode(query, convert_to_tensor=True)\n",
        "    similarities = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
        "    semantic_top_idx = torch.argsort(similarities, descending=True).cpu().numpy()[:100]\n",
        "\n",
        "    # Combine results from BM25 and semantic search for reranking\n",
        "    combined_idx = np.unique(np.concatenate([bm25_top_idx, semantic_top_idx]))\n",
        "\n",
        "    # Prepare the reranking input and perform cross-encoder reranking\n",
        "    rerank_corpus = [corpus[idx] for idx in combined_idx]\n",
        "    rerank_input = [[query, passage] for passage in rerank_corpus]\n",
        "    rerank_scores = cross_encoder.predict(rerank_input)\n",
        "\n",
        "    # Select the top results after reranking\n",
        "    top_indices = np.argsort(rerank_scores)[::-1][:top_k]\n",
        "\n",
        "    print(\"Query:\", query)\n",
        "    print(\"\\nTop 5 most relevant movies:\")\n",
        "    for idx in top_indices:\n",
        "        original_idx = combined_idx[idx]\n",
        "        print(data.iloc[original_idx]['Title'])\n",
        "\n",
        "# Get a search query from the user\n",
        "user_query = input(\"Enter your movie plot query: \")\n",
        "search_and_rerank(user_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9woJuAdr_Ig",
        "outputId": "f8fa0abb-7a56-447c-abc3-54edc76943d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your movie plot query: Documentaries showcasing indigenous peoples' survival and daily life in Arctic regions\n",
            "Query: Documentaries showcasing indigenous peoples' survival and daily life in Arctic regions\n",
            "\n",
            "Top 5 most relevant movies:\n",
            "The Savage Innocents\n",
            "The Last Wave\n",
            "Nanook of the North\n",
            "Searchers (Maliglutit)\n",
            "The White Dawn\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us calculate the values of @Recall and @MRR now. Recall@k = true positives@k + true negatives@k\n",
        "\n",
        "Documentaries showcasing indigenous pepoles survival and daily life in arctic regions The top 5 results for this query are : The savage innocents, the last wave, nanook of the north,searchers,the white dawn out of these five results, The savage innocents- RELEVANT, The last wave - IRRELEVANT, searchers - RELEVANT,Nanook of north- Irrelevant, The white dawn- IRRELEVANT\n",
        "\n",
        " Recall@1 = 1/(1+2)= 0.33\n",
        "\n",
        "The metric is useful when we our system to return the best relevant item and want that item to be at higher position. The top 5 results for this query are :The savage innocents, the last wave, nanook of the north,searchers,the white dawn For this query, the reciporcal rank is 1/1 and MRR=1 (as the first correct item is at position)"
      ],
      "metadata": {
        "id": "7QfmiChn5mq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
        "from rank_bm25 import BM25Okapi\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_csv('/content/processed_movies.csv')\n",
        "\n",
        "# Combine 'Title' and 'Plot' for indexing\n",
        "corpus = [f\"{row['Title']}: {row['Plot']}\" for _, row in data.iterrows()]\n",
        "\n",
        "# Tokenize the corpus for BM25\n",
        "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "# Load the bi-encoder model\n",
        "bi_encoder = SentenceTransformer('nq-distilbert-base-v1')\n",
        "corpus_embeddings = bi_encoder.encode(corpus, convert_to_tensor=True)\n",
        "\n",
        "# Load the cross-encoder model for reranking\n",
        "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "\n",
        "# Function to search and rerank the corpus\n",
        "def search_and_rerank(query: str, top_k: int = 5):\n",
        "    # Perform BM25 search to get a broader set of candidates\n",
        "    bm25_scores = bm25.get_scores(query.split(\" \"))\n",
        "    bm25_top_idx = np.argsort(bm25_scores)[::-1][:100]\n",
        "\n",
        "    # Semantic search to refine the candidates\n",
        "    query_embedding = bi_encoder.encode(query, convert_to_tensor=True)\n",
        "    similarities = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
        "    semantic_top_idx = torch.argsort(similarities, descending=True).cpu().numpy()[:100]\n",
        "\n",
        "    # Combine results from BM25 and semantic search for reranking\n",
        "    combined_idx = np.unique(np.concatenate([bm25_top_idx, semantic_top_idx]))\n",
        "\n",
        "    # Prepare the reranking input and perform cross-encoder reranking\n",
        "    rerank_corpus = [corpus[idx] for idx in combined_idx]\n",
        "    rerank_input = [[query, passage] for passage in rerank_corpus]\n",
        "    rerank_scores = cross_encoder.predict(rerank_input)\n",
        "\n",
        "    # Select the top results after reranking\n",
        "    top_indices = np.argsort(rerank_scores)[::-1][:top_k]\n",
        "\n",
        "    print(\"Query:\", query)\n",
        "    print(\"\\nTop 5 most relevant movies:\")\n",
        "    for idx in top_indices:\n",
        "        original_idx = combined_idx[idx]\n",
        "        print(data.iloc[original_idx]['Title'])\n",
        "\n",
        "# Get a search query from the user\n",
        "user_query = input(\"Enter your movie plot query: \")\n",
        "search_and_rerank(user_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSCL-OnLwmtE",
        "outputId": "41a13571-fa9a-4cea-c37f-9d814449c00b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your movie plot query: Western romance\n",
            "Query: Western romance\n",
            "\n",
            "Top 5 most relevant movies:\n",
            "El Akhar (The Other)\n",
            "The Big Show\n",
            "The Magic of Belle Isle\n",
            "Saturday's Millions\n",
            "This Is Not What I Expected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us calculate the values of @Recall and @MRR now. Recall@k = true positives@k + true negatives@k\n",
        "\n",
        "Documentaries showcasing indigenous pepoles survival and daily life in arctic regions The top 5 results for this query are :El akhar,The big show,The magic of belle isle,saturdays millions, this is not what i expected out of these five results,\n",
        "\n",
        " Recall@1 = 1/(1+1)= 0.5\n",
        "\n",
        "The metric is useful when we our system to return the best relevant item and want that item to be at higher position. The top 5 results for this query are :l aEl akhar,The big show,The magic of belle isle,saturdays millions, this is not what i expected   For this query, the reciporcal rank is 1/1 and MRR=1 (as the first correct item is at position)"
      ],
      "metadata": {
        "id": "V9XlRU1W5oL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
        "from rank_bm25 import BM25Okapi\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_csv('/content/processed_movies.csv')\n",
        "\n",
        "# Combine 'Title' and 'Plot' for indexing\n",
        "corpus = [f\"{row['Title']}: {row['Plot']}\" for _, row in data.iterrows()]\n",
        "\n",
        "# Tokenize the corpus for BM25\n",
        "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "# Load the bi-encoder model\n",
        "bi_encoder = SentenceTransformer('nq-distilbert-base-v1')\n",
        "corpus_embeddings = bi_encoder.encode(corpus, convert_to_tensor=True)\n",
        "\n",
        "# Load the cross-encoder model for reranking\n",
        "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "\n",
        "# Function to search and rerank the corpus\n",
        "def search_and_rerank(query: str, top_k: int = 5):\n",
        "    # Perform BM25 search to get a broader set of candidates\n",
        "    bm25_scores = bm25.get_scores(query.split(\" \"))\n",
        "    bm25_top_idx = np.argsort(bm25_scores)[::-1][:100]\n",
        "\n",
        "    # Semantic search to refine the candidates\n",
        "    query_embedding = bi_encoder.encode(query, convert_to_tensor=True)\n",
        "    similarities = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
        "    semantic_top_idx = torch.argsort(similarities, descending=True).cpu().numpy()[:100]\n",
        "\n",
        "    # Combine results from BM25 and semantic search for reranking\n",
        "    combined_idx = np.unique(np.concatenate([bm25_top_idx, semantic_top_idx]))\n",
        "\n",
        "    # Prepare the reranking input and perform cross-encoder reranking\n",
        "    rerank_corpus = [corpus[idx] for idx in combined_idx]\n",
        "    rerank_input = [[query, passage] for passage in rerank_corpus]\n",
        "    rerank_scores = cross_encoder.predict(rerank_input)\n",
        "\n",
        "    # Select the top results after reranking\n",
        "    top_indices = np.argsort(rerank_scores)[::-1][:top_k]\n",
        "\n",
        "    print(\"Query:\", query)\n",
        "    print(\"\\nTop 5 most relevant movies:\")\n",
        "    for idx in top_indices:\n",
        "        original_idx = combined_idx[idx]\n",
        "        print(data.iloc[original_idx]['Title'])\n",
        "\n",
        "# Get a search query from the user\n",
        "user_query = input(\"Enter your movie plot query: \")\n",
        "search_and_rerank(user_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6mfEJK8wnqg",
        "outputId": "c413235f-8048-4d75-816e-1ad1bc632929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your movie plot query: \"Silent film about a Parisian star moving to Egypt, leaving her husband for a baron, and later reconciling after finding her family in poverty in Cairo\n",
            "Query: \"Silent film about a Parisian star moving to Egypt, leaving her husband for a baron, and later reconciling after finding her family in poverty in Cairo\n",
            "\n",
            "Top 5 most relevant movies:\n",
            "Sahara\n",
            "He Who Gets Slapped\n",
            "Death on the Nile\n",
            "Cairo Time\n",
            "The Suburbanite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us calculate the values of @Recall and @MRR now. Recall@k = true positives@k + true negatives@k\n",
        "\n",
        "Documentaries showcasing indigenous pepoles survival and daily life in arctic regions The top 5 results for this query are : Sahara, he who gets slapped, death on the nile, cairo time, The suburbanite out of these five results,\n",
        "\n",
        " Recall@1 = 1/(1+1)= 0.5\n",
        "\n",
        "The metric is useful when we our system to return the best relevant item and want that item to be at higher position. The top 5 results for this query are : Sahara, he who gets slapped, death on the nile, cairo time, The suburbanite For this query, the reciporcal rank is 1/1 and MRR=1 (as the first correct item is at position)"
      ],
      "metadata": {
        "id": "9ggaMDT25pe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
        "from rank_bm25 import BM25Okapi\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_csv('/content/processed_movies.csv')\n",
        "\n",
        "# Combine 'Title' and 'Plot' for indexing\n",
        "corpus = [f\"{row['Title']}: {row['Plot']}\" for _, row in data.iterrows()]\n",
        "\n",
        "# Tokenize the corpus for BM25\n",
        "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "# Load the bi-encoder model\n",
        "bi_encoder = SentenceTransformer('nq-distilbert-base-v1')\n",
        "corpus_embeddings = bi_encoder.encode(corpus, convert_to_tensor=True)\n",
        "\n",
        "# Load the cross-encoder model for reranking\n",
        "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "\n",
        "# Function to search and rerank the corpus\n",
        "def search_and_rerank(query: str, top_k: int = 5):\n",
        "    # Perform BM25 search to get a broader set of candidates\n",
        "    bm25_scores = bm25.get_scores(query.split(\" \"))\n",
        "    bm25_top_idx = np.argsort(bm25_scores)[::-1][:100]\n",
        "\n",
        "    # Semantic search to refine the candidates\n",
        "    query_embedding = bi_encoder.encode(query, convert_to_tensor=True)\n",
        "    similarities = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
        "    semantic_top_idx = torch.argsort(similarities, descending=True).cpu().numpy()[:100]\n",
        "\n",
        "    # Combine results from BM25 and semantic search for reranking\n",
        "    combined_idx = np.unique(np.concatenate([bm25_top_idx, semantic_top_idx]))\n",
        "\n",
        "    # Prepare the reranking input and perform cross-encoder reranking\n",
        "    rerank_corpus = [corpus[idx] for idx in combined_idx]\n",
        "    rerank_input = [[query, passage] for passage in rerank_corpus]\n",
        "    rerank_scores = cross_encoder.predict(rerank_input)\n",
        "\n",
        "    # Select the top results after reranking\n",
        "    top_indices = np.argsort(rerank_scores)[::-1][:top_k]\n",
        "\n",
        "    print(\"Query:\", query)\n",
        "    print(\"\\nTop 5 most relevant movies:\")\n",
        "    for idx in top_indices:\n",
        "        original_idx = combined_idx[idx]\n",
        "        print(data.iloc[original_idx]['Title'])\n",
        "\n",
        "# Get a search query from the user\n",
        "user_query = input(\"Enter your movie plot query: \")\n",
        "search_and_rerank(user_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHqjK7vgwo0W",
        "outputId": "42936bcd-5329-4b0e-f25b-fde3bf0aba08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your movie plot query: \"Comedy film, office disguises, boss's daughter, elopement.\n",
            "Query: \"Comedy film, office disguises, boss's daughter, elopement.\n",
            "\n",
            "Top 5 most relevant movies:\n",
            "Bucking Broadway\n",
            "Mabel's Blunder\n",
            "The Double\n",
            "He Hired the Boss\n",
            "The Bedroom Window\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us calculate the values of @Recall and @MRR now. Recall@k = true positives@k + true negatives@k\n",
        "\n",
        "Documentaries showcasing indigenous pepoles survival and daily life in arctic regions The top 5 results for this query are : Bucking broadway, mabels blunder, the double, he hired the boss, the bedroom window. out of these five results,\n",
        "\n",
        " Recall@1 = 1/(1+1)= 0.5\n",
        "\n",
        "The metric is useful when we our system to return the best relevant item and want that item to be at higher position. The top 5 results for this query are :  Bucking broadway, mabels blunder, the double, he hired the boss, the bedroom window For this query, the reciporcal rank is 1/1 and MRR=1 (as the first correct item is at position)"
      ],
      "metadata": {
        "id": "DYZRaKEU5rJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
        "from rank_bm25 import BM25Okapi\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_csv('/content/processed_movies.csv')\n",
        "\n",
        "# Combine 'Title' and 'Plot' for indexing\n",
        "corpus = [f\"{row['Title']}: {row['Plot']}\" for _, row in data.iterrows()]\n",
        "\n",
        "# Tokenize the corpus for BM25\n",
        "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "# Load the bi-encoder model\n",
        "bi_encoder = SentenceTransformer('nq-distilbert-base-v1')\n",
        "corpus_embeddings = bi_encoder.encode(corpus, convert_to_tensor=True)\n",
        "\n",
        "# Load the cross-encoder model for reranking\n",
        "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "\n",
        "# Function to search and rerank the corpus\n",
        "def search_and_rerank(query: str, top_k: int = 5):\n",
        "    # Perform BM25 search to get a broader set of candidates\n",
        "    bm25_scores = bm25.get_scores(query.split(\" \"))\n",
        "    bm25_top_idx = np.argsort(bm25_scores)[::-1][:100]\n",
        "\n",
        "    # Semantic search to refine the candidates\n",
        "    query_embedding = bi_encoder.encode(query, convert_to_tensor=True)\n",
        "    similarities = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
        "    semantic_top_idx = torch.argsort(similarities, descending=True).cpu().numpy()[:100]\n",
        "\n",
        "    # Combine results from BM25 and semantic search for reranking\n",
        "    combined_idx = np.unique(np.concatenate([bm25_top_idx, semantic_top_idx]))\n",
        "\n",
        "    # Prepare the reranking input and perform cross-encoder reranking\n",
        "    rerank_corpus = [corpus[idx] for idx in combined_idx]\n",
        "    rerank_input = [[query, passage] for passage in rerank_corpus]\n",
        "    rerank_scores = cross_encoder.predict(rerank_input)\n",
        "\n",
        "    # Select the top results after reranking\n",
        "    top_indices = np.argsort(rerank_scores)[::-1][:top_k]\n",
        "\n",
        "    print(\"Query:\", query)\n",
        "    print(\"\\nTop 5 most relevant movies:\")\n",
        "    for idx in top_indices:\n",
        "        original_idx = combined_idx[idx]\n",
        "        print(data.iloc[original_idx]['Title'])\n",
        "\n",
        "# Get a search query from the user\n",
        "user_query = input(\"Enter your movie plot query: \")\n",
        "search_and_rerank(user_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0fXNFvLwplw",
        "outputId": "79352220-9d76-42eb-e4c7-86b7fadc7bde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your movie plot query: \"Lost film, Cleopatra charms Caesar, plots world rule, treasures from mummy, revels with Antony, tragic end with serpent in Alexandria\n",
            "Query: \"Lost film, Cleopatra charms Caesar, plots world rule, treasures from mummy, revels with Antony, tragic end with serpent in Alexandria\n",
            "\n",
            "Top 5 most relevant movies:\n",
            "Cleopatra\n",
            "Serpent of the Nile\n",
            "Carry On Cleo\n",
            "Caesar and Cleopatra\n",
            "Cleopatra\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us calculate the values of @Recall and @MRR now. Recall@k = true positives@k + true negatives@k\n",
        "\n",
        "Documentaries showcasing indigenous pepoles survival and daily life in arctic regions The top 5 results for this query are :Cleopatra, serpent of the nile, carry on cleo, caesar and cleopatra, cleopatra out of these five results,\n",
        "\n",
        " Recall@1 = 1/(1+2)= 0.33\n",
        "\n",
        "The metric is useful when we our system to return the best relevant item and want that item to be at higher position. The top 5 results for this query are :Cleopatra, serpent of the nile, carry on cleo, caesar and cleopatra, cleopatra For this query, the reciporcal rank is 1/3 and MRR=3"
      ],
      "metadata": {
        "id": "-cLmzjk55s5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer, CrossEncoder, util\n",
        "from rank_bm25 import BM25Okapi\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_csv('/content/processed_movies.csv')\n",
        "\n",
        "# Combine 'Title' and 'Plot' for indexing\n",
        "corpus = [f\"{row['Title']}: {row['Plot']}\" for _, row in data.iterrows()]\n",
        "\n",
        "# Tokenize the corpus for BM25\n",
        "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "# Load the bi-encoder model\n",
        "bi_encoder = SentenceTransformer('nq-distilbert-base-v1')\n",
        "corpus_embeddings = bi_encoder.encode(corpus, convert_to_tensor=True)\n",
        "\n",
        "# Load the cross-encoder model for reranking\n",
        "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "\n",
        "# Function to search and rerank the corpus\n",
        "def search_and_rerank(query: str, top_k: int = 5):\n",
        "    # Perform BM25 search to get a broader set of candidates\n",
        "    bm25_scores = bm25.get_scores(query.split(\" \"))\n",
        "    bm25_top_idx = np.argsort(bm25_scores)[::-1][:100]\n",
        "\n",
        "    # Semantic search to refine the candidates\n",
        "    query_embedding = bi_encoder.encode(query, convert_to_tensor=True)\n",
        "    similarities = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
        "    semantic_top_idx = torch.argsort(similarities, descending=True).cpu().numpy()[:100]\n",
        "\n",
        "    # Combine results from BM25 and semantic search for reranking\n",
        "    combined_idx = np.unique(np.concatenate([bm25_top_idx, semantic_top_idx]))\n",
        "\n",
        "    # Prepare the reranking input and perform cross-encoder reranking\n",
        "    rerank_corpus = [corpus[idx] for idx in combined_idx]\n",
        "    rerank_input = [[query, passage] for passage in rerank_corpus]\n",
        "    rerank_scores = cross_encoder.predict(rerank_input)\n",
        "\n",
        "    # Select the top results after reranking\n",
        "    top_indices = np.argsort(rerank_scores)[::-1][:top_k]\n",
        "\n",
        "    print(\"Query:\", query)\n",
        "    print(\"\\nTop 5 most relevant movies:\")\n",
        "    for idx in top_indices:\n",
        "        original_idx = combined_idx[idx]\n",
        "        print(data.iloc[original_idx]['Title'])\n",
        "\n",
        "# Get a search query from the user\n",
        "user_query = input(\"Enter your movie plot query: \")\n",
        "search_and_rerank(user_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pu7ewEKcwqkx",
        "outputId": "933a911a-b381-4c78-d61e-6297e9ca869c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your movie plot query: Denis Gage Deane-Tanner\n",
            "Query: Denis Gage Deane-Tanner\n",
            "\n",
            "Top 5 most relevant movies:\n",
            "Captain Alvarez\n",
            "I Love You, Beth Cooper\n",
            "Skin & Bone\n",
            "Dean\n",
            "Indecent Proposal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us calculate the values of @Recall and @MRR now. Recall@k = true positives@k + true negatives@k\n",
        "\n",
        "Documentaries showcasing indigenous pepoles survival and daily life in arctic regions The top 5 results for this query are :Captain Alvarez, I Love You,Beth Cooper, Skin & bone,Dean,Indecent Proposal out of these five results,\n",
        "\n",
        " Recall@1 = 1/(1+1)= 0.5\n",
        "\n",
        "The metric is useful when we our system to return the best relevant item and want that item to be at higher position. The top 5 results for this query are : Captain Alvarez, I Love You,Beth Cooper, Skin & bone,Dean,Indecent Proposal For this query, the reciporcal rank is 1/1 and MRR=1 (as the first correct item is at position)"
      ],
      "metadata": {
        "id": "_-EDeg_C5ucO"
      }
    }
  ]
}